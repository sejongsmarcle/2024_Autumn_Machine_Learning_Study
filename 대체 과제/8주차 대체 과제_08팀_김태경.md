### 1. 데이터셋의 차원을 축소하는 주요 목적과 대표적인 단점
 * 주요 목적 : 고차원 데이터는 훈련도 느리고, 좋은 솔루션을 발견하기 어려움
 * 단점 : 작업 파이프라인이 좀 더 복잡해지고, 유지관리가 어려움. 시스템의 성능 저하로 이어지는 경우도 간혹 존재
### 2. '차원의 저주'란?
많은 특성을 가진 데이터가 오히려 훈련을 방해하고, 좋지 않은 결과를 내는 문제를 말함.

### 3. 데이터셋의 차원 축소 후 이를 원상복구 가능한가? 가능하다면 어떻게? 아니라면 그 이유는?
불가능. 투영 과정에서 기존의 정보가 손실되기 때문.

### 4. 매우 비선형적인 데이터셋의 차원 축소에 PCA를 사용 가능한가?
불가능. 스위 롤 데이터셋 등은 PCA를 사용하면 정보 손실이 너무 많음.

### 5. 설명된 분산을 95%로 지정한 PCA를 1000개 차원의 데이터셋에 적용할 때 결과 데이터셋의 차원은?
784개 차원의 데이터가 23개 차원으로 줄어든 걸로 보아 50차원 이내로 나올 것으로 추정.

### 6. 기본 PCA, 점진적 PCA, 랜덤 PCA, 랜덤 투영은 각각 어느 경우에 사용되는가?
 * 기본 PCA : 데이터셋의 차원을 줄여야 할 때
 * 점진적 PCA : 실시간으로 새로운 데이터에 대해 적용해야 하는 경우
 * 랜덤 PCA : 처음 몇 개의 주성분에 대한 근삿값을 빠르게 찾는 경우
 * 랜덤 투영 : 대규모 데이터셋의 차원을 줄이는 경우

### 7. 차원 축소 알고리즘의 성능 평가 방법
재구성 오차 등을 이용해 얼마나 원본의 성질을 잘 유지하고 있으면서 축소되었는지 평가할 수 있다.

### 8. 두 개의 차원 축소 알고리즘을 연결할 수 있는가?
가능. 2개 이상을 연결해 사용하는 것으로 더 효과적인 차원 축소가 가능하기도 함.
