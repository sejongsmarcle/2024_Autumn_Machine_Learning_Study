

1. 데이터셋의 차원을 축소하는 주요 목적은 무엇인가요? 대표적인 단점은 무엇인가요?
    
    ⇒ 실제 데이터의 경우, 셀 수 없이 많은 특성을 가지고 있어 훈련 속도가 매우 느리고, 좋은 솔루션 찾기가 어렵기 때문에 차원을 축소한다. 하지만, 차원을 축소시키면 일부 정보가 유실돼 작업 과정이 조금 더 복잡해지고 유지 관리가 어려워진다.
    
2. 차원의 저주란 무엇인가요?
    
    ⇒ 데이터의 차원이 높아질 수록 알고리즘의 훈련 속도가 매우 느리고, 좋은 솔루션을 찾기 어려운 일을 의미한다.
    
3. 데이터셋의 차원을 축소시키고 나서 이 작업을 원상 복구할 수 있나요? 할 수 있다면 어떻게 가능할까요? 가능하지 않다면 왜일까요?
    
    ⇒ PCA 투영의 변환을 반대로 적용하게 되면 원래의 차원으로 되돌릴 수 있지만, 투영에서 일정 정보를 유실하기 때문에 원본 데이터셋으로 원상 복구할 수 없다. 
    
4. 매우 비선형적인 데이터셋의 차원을 축소하는 데 PCA를 사용할 수 있을까요?
    
    ⇒ PCA의 경우, 불필요한 차원을 제거할 수 있어 데이터셋에서 차원을 축소하는 데 사용할 수 있다. 하지만, 특정 데이터에서는 정보 유실이 매우 많이 일어날 수 있기 때문에 주의해서 사용해야 한다.
    
5. 설명된 분산을 95%로 지정한 PCA를 1,000개의 차원을 가진 데이터셋에 적용한다고 가정하겠습니다. 결과 데이터셋의 차원은 얼마나 될까요?
→ 데이터셋에 따라 다르다.
→ 데이터의 개수보다, 그 데이터의 분산에 따라 축소될 차원의 개수가 다를 수 있다.
6. 기본 PCA, 점진적 PCA, 랜덤 PCA, 랜덤 투영은 각각 어느 경우에 사용될까요?
→ 기본 PCA : 데이터셋 크기가 메모리에 맞을 때 가능하다.
→ 점진적 PCA : 훈련 세트가 클 때 유용하다.
→ 랜덤 PCA : d가 n보다 작을 때 가능합니다.
→ 랜덤 투영 : 고차원 데이터셋에서 유리합니다.
7. 어떤 데이터셋에 적용한 차원 축소 알고리즘의 성능을 어떻게 평가할 수 있을까요?
→ TSNE, PCA 기법, 지역적 선형 임베딩, MDS 등이 사용될 수 있다.
→ 역변환을 수행하여 재구성 오차를 측정한다.
→ 그러나 모든 상황에 사용 가능한 것은 아니다.
→ 차원 축소로 너무 많은 정보를 잃지 않았다면 원본 데이터셋을 사용했을 때와 비슷한 성능이 나와야 한다.
8. 두 개의 차원 축소 알고리즘을 연결할 수 있을까요?
→ PCA로 불필요한 차원을 제거한 후 LLE 사용하는 등의 방식이 있다.

